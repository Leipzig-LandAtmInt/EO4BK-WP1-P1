{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LUCAS 2018/2022 data preprocessing to create EO4BK Nomenclature crop classes\n",
    "\n",
    "In this latest version of D2.1_v01, the new nomenclature (proposed in the D1.1 document dated 05/11/2024) is used to create the LUCAS reference dataset. In version D2.1_v00, the nomenclature of the proposal was used. \n",
    "\n",
    "## Table of content  \n",
    "\n",
    "1. [Load data](#1-load-data)\n",
    "2. [Reduce and Split](#2-reduce-and-split)\n",
    "3. [Create Class for data with a low detail level](#3-create-class-for-data-with-a-low-detail-level)\n",
    "4. [Create Class for data with a high detail level](#4-Create-class-for-data-with-a-high-detail-level)\n",
    "5. [Create Function to merge low detail level and high detail level](#5-create-function-to-merge-low-detail-level-and-high-detail-level)\n",
    "6. [Create final EO4BKLUCAS dataset](#6-create-final-eo4bklucas-dataset)\n",
    "7. [Save EO4BKLUCAS dataset](#7-save-eo4bklucas-dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "LUCAS = os.getenv('LUCAS_D21_V01')\n",
    "\n",
    "# load LUCAS COPERNICUS 2022 data \n",
    "\n",
    "lcs2022 = gpd.read_file(f'{LUCAS}/lucas_input_data/l2022_survey_cop_radpoly_attr.gpkg')\n",
    "# subset polygons larger than 100 sqm\n",
    "\n",
    "lcs2022 = lcs2022[lcs2022['poly_area_sqm'] >= 100]\n",
    "# load LUCAS COPERNICUS 2018 data\n",
    "\n",
    "lcs2018_hd_data = gpd.read_file(f'{LUCAS}/lucas_input_data/LUCAS_2018_U111_TRUE.gpkg')\n",
    "\n",
    "# calculate area \n",
    "lcs2018_hd_data = lcs2018_hd_data.to_crs(crs = lcs2022.crs)\n",
    "lcs2018_hd_data['poly_area_sqm'] = lcs2018_hd_data.area      # returns a series containing the area of each geometry in the geoseries expressed in the units of the CRS\n",
    "lcs2018_hd_data = lcs2018_hd_data[lcs2018_hd_data['poly_area_sqm'] >= 100]\n",
    "\n",
    "# Defind data type if needed \n",
    "lcs2022['survey_lc1_perc'] = pd.to_numeric(lcs2022['survey_lc1_perc'])\n",
    "lcs2022['survey_lc1'] = lcs2022['survey_lc1'].astype(str)\n",
    "lcs2022['survey_lu1'] = lcs2022['survey_lu1'].astype(str)\n",
    "lcs2022['survey_lc2'] = lcs2022['survey_lc2'].astype(str)\n",
    "lcs2022['survey_lu2'] = lcs2022['survey_lu2'].astype(str)\n",
    "lcs2022['surveycprnlc'] = lcs2022['surveycprnlc'].astype(str)\n",
    "lcs2022['survey_calc_dist'] = pd.to_numeric(lcs2022['survey_calc_dist'])\n",
    "lcs2022['nuts0'] = lcs2022['nuts0'].astype(str) \n",
    "lcs2022['nuts1'] = lcs2022['nuts1'].astype(str) \n",
    "lcs2022['nuts2'] = lcs2022['nuts2'].astype(str) \n",
    "lcs2022['nuts3'] = lcs2022['nuts3'].astype(str) \n",
    "lcs2022['survey_date'] = pd.to_datetime(lcs2022['survey_date'])\n",
    "lcs2022['survey_date'] = lcs2022['survey_date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reduce and Split \n",
    "\n",
    "From lc2022 only data with U111 'Agriculture (excluding fallow land and kitchen gardens)' == True is used. This subset is further divided into LUCAS Copernicus module (lcscpncs) and LUCAS theoretical points (lcstheo). \n",
    "Check whether the lcstheo and lcscpncs spatially agrees (Yes/No). If \"No\": ld_data, if \"Yes\": Check if lcstheo and lcspncs LC agrees (Yes/No). If \"No\": Remove data, if \"Yes\": hd_data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only U111\n",
    "lcs2022_u111 = lcs2022[(lcs2022['survey_lu1'].str.slice(0,4) == 'U111') | (lcs2022['survey_lu2'].str.slice(0,4) == 'U111') | (lcs2022['lu1_code'] == 'U111')]\n",
    "\n",
    "# Coordinates from lcs2022 that belongs to lucastheo\n",
    "lcstheo = pd.DataFrame(index = lcs2022_u111.index)\n",
    "lcstheo['lon'] = lcs2022_u111['point_long']\n",
    "lcstheo['lat'] = lcs2022_u111['point_lat']\n",
    "\n",
    "# the lucas theoretical points are in EPSGG:4326, while the polygons are in EPSG:3035 # https://ec.europa.eu/eurostat/documents/205002/13686460/C1-LUCAS-2022.pdf\n",
    "lcstheo = gpd.GeoSeries(gpd.points_from_xy(lcstheo.lon, lcstheo.lat, crs = \"EPSG:4326\")) \n",
    "# change to EPSG: 3035\n",
    "lcstheo = lcstheo.to_crs(lcs2022_u111.crs) \n",
    "\n",
    "# Create Subset of data that spatially agrees == No\n",
    "spatially_agree_boolean = lcstheo.within(lcs2022_u111.geometry, align = False)\n",
    "spatially_agree_boolean.index = lcs2022_u111.index\n",
    "lcs2022_ld_data = lcs2022_u111[spatially_agree_boolean == False]\n",
    "\n",
    "# Create Subset of data that spatially agrees == Yes\n",
    "spatially_agree_boolean = lcstheo.within(lcs2022_u111.geometry, align = False)\n",
    "spatially_agree_boolean.index = lcs2022_u111.index\n",
    "spatially_agree = lcs2022_u111[spatially_agree_boolean]\n",
    "\n",
    "# Check from spatially agrees == Yes, whether LC between lcstheo and lcscpncs agree or dont agree? \n",
    "\n",
    "## LC agrees == No\n",
    "error_data = spatially_agree[(spatially_agree['survey_lc1'].str.slice(0,3) != spatially_agree['surveycprnlc'])&(spatially_agree['survey_lc2'].str.slice(0,3) != spatially_agree['surveycprnlc'])]\n",
    "\n",
    "## LC agrees == Yes\n",
    "lcs2022_hd_data = spatially_agree[(spatially_agree['survey_lc1'].str.slice(0,3) == spatially_agree['surveycprnlc'])|(spatially_agree['survey_lc2'].str.slice(0,3) == spatially_agree['surveycprnlc'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename LUCAS 2018 to fit LUCAS 2022\n",
    "\n",
    "For LUCAS 2018: 'survey_wm_reclaim_signs', 'survey_inspire_unvegetated', 'survey_lm_stand_veget', 'survey_lm_by_veget', 'survey_lm_crop_resid', 'survey_lm_crop_resid_perc' is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248891/1346486659.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  lcs2018_hd_data['survey_date'] = pd.to_datetime(lcs2018_hd_data['survey_date'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lcs2018_hd_data = lcs2018_hd_data.rename(columns=str.lower)\n",
    "lcs2018_hd_data = lcs2018_hd_data.rename(columns={'year':'survey_year',\n",
    "                                                  'lc1':'survey_lc1',\n",
    "                                                  'lc2':'survey_lc2',\n",
    "                                                  'lc1_spec':'survey_lc1_spec',\n",
    "                                                  'lc2_spec':'survey_lc2_spec',\n",
    "                                                  'cprn_lc':'surveycprnlc',\n",
    "                                                  'wm':'survey_wm',\n",
    "                                                  'wm_source':'survey_wm_source',\n",
    "                                                  'wm_type':'survey_wm_type',\n",
    "                                                  'wm_delivery':'survey_wm_delivery',\n",
    "                                                  'crop_residues':'survey_lm_crop_resid',\n",
    "                                                  'lc_lu_special_remark':'survey_lc_lu_special_remark'})\n",
    "\n",
    "\n",
    "lcs2018_hd_data['survey_date'] = pd.to_datetime(lcs2018_hd_data['survey_date'])\n",
    "lcs2018_hd_data['survey_date'] = lcs2018_hd_data['survey_date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "\n",
    "# Because for LUCAS 2018 '8 Not relevant' is written as '8', harmonize that field \n",
    "lcs2018_hd_data['survey_lc2'] = np.where(\n",
    "    lcs2018_hd_data['survey_lc2'] == '8',\n",
    "    '8 - Not relevant',\n",
    "    lcs2018_hd_data['survey_lc2']\n",
    ")\n",
    "\n",
    "lcs2018_hd_data['survey_lc1_spec'] = np.where(\n",
    "    lcs2018_hd_data['survey_lc1_spec'] == '8',\n",
    "    '8 - Not relevant',\n",
    "    lcs2018_hd_data['survey_lc1_spec']\n",
    ")\n",
    "\n",
    "lcs2018_hd_data['survey_lc2_spec'] = np.where(\n",
    "    lcs2018_hd_data['survey_lc2_spec'] == '8',\n",
    "    '8 - Not relevant',\n",
    "    lcs2018_hd_data['survey_lc2_spec']\n",
    ")\n",
    "\n",
    "# because the last letter of 2018 is written in capital letters, unlike for LUCAS 2022, where the last letter is lower case. \n",
    "\n",
    "lcs2018_hd_data['survey_lc1_spec'] = np.where(\n",
    "    lcs2018_hd_data['survey_lc1_spec'] != '8 - Not relevant',\n",
    "    lcs2018_hd_data['survey_lc1_spec'].str.capitalize(),\n",
    "    lcs2018_hd_data['survey_lc1_spec']\n",
    ")\n",
    "\n",
    "lcs2018_hd_data['survey_lc2_spec'] = np.where(\n",
    "    lcs2018_hd_data['survey_lc2_spec'] != '8 - Not relevant',\n",
    "    lcs2018_hd_data['survey_lc2_spec'].str.capitalize(),\n",
    "    lcs2018_hd_data['survey_lc2_spec']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Create Class for data with a low detail level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lowdetail:\n",
    "\n",
    "    def __init__(self, ld_data, eo4bkclass,year = ['2018','2022'], **kwargs):\n",
    "        \n",
    "        self.ld_data = ld_data \n",
    "        self.eo4bkclass = eo4bkclass\n",
    "        self.year = year\n",
    "        lc1 = kwargs.get('lc1')\n",
    "        lc2 = kwargs.get('lc2')\n",
    "        lc3 = kwargs.get('lc3')\n",
    "\n",
    "\n",
    "\n",
    "        self.class_list = [lc for lc in [lc1,lc2,lc3] if lc is not None]\n",
    "\n",
    "        self.ld_class = self.filter_subset()\n",
    "        self.ld_gdf = self.create_ld_gdf()\n",
    "    \n",
    "    def filter_subset(self):\n",
    "        ld_class = pd.DataFrame()\n",
    "        for i in self.class_list:\n",
    "            filtered_ld_data = self.ld_data[self.ld_data['surveycprnlc'] == i]\n",
    "            ld_class = pd.concat([ld_class, filtered_ld_data], ignore_index= True)\n",
    "        return ld_class\n",
    "\n",
    "    \n",
    "    def create_ld_gdf(self):\n",
    "        '''\n",
    "        Creates GeoDataframe from input LC class, with just these Attributes from the LUCAS dataset, that are collected in the COPERNICUS module\n",
    "        '''\n",
    "        year = self.year\n",
    "        ld_gdf = gpd.GeoDataFrame({'point_id': [],\n",
    "                                    f'survey_date_{year}': [],\n",
    "                                    f'survey_year_{year}': [],\n",
    "                                    'nuts0' :[], \n",
    "                                    'nuts1' :[],\n",
    "                                    'nuts2' : [],\n",
    "                                    'nuts3'  : [],\n",
    "                                    'poly_area_sqm' : [], \n",
    "                                    f'lc3_{year}':[],\n",
    "                                    f'lc_eo4bk_{year}': [],\n",
    "                                    'geometry': []\n",
    "                                    }, \n",
    "                                    crs = self.ld_data.crs)\n",
    "        \n",
    "        ld_gdf['point_id']      = self.ld_class['point_id'].astype(str)\n",
    "        ld_gdf[f'survey_date_{year}']   = pd.to_datetime(self.ld_class['survey_date'])\n",
    "        ld_gdf[f'survey_year_{year}']   = self.ld_class['survey_year']\n",
    "        ld_gdf[f'nuts0']         = self.ld_class['nuts0'].astype(str)\n",
    "        ld_gdf[f'nuts1']         = self.ld_class['nuts1'].astype(str)\n",
    "        ld_gdf[f'nuts2']         = self.ld_class['nuts2'].astype(str)\n",
    "        ld_gdf['nuts3']         = self.ld_class['nuts3'].astype(str)\n",
    "        ld_gdf['poly_area_sqm'] = round(self.ld_class['poly_area_sqm'].astype(float), 2)\n",
    "        ld_gdf[f'lc3_{year}']           = self.ld_class['surveycprnlc']\n",
    "        ld_gdf[f'lc_eo4bk_{year}']      = self.eo4bkclass\n",
    "        ld_gdf['geometry']      = self.ld_class.geometry\n",
    "\n",
    "        return ld_gdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Class for data with a high detail level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class highdetail:\n",
    "\n",
    "    def __init__(self, hd_data, eo4bkclass, year = ['2018','2022'], **kwargs):\n",
    "        self.hd_data = hd_data\n",
    "        self.eo4bkclass = eo4bkclass\n",
    "        self.year = year\n",
    "\n",
    "        lc1 = kwargs.get('lc1')\n",
    "        lc2 = kwargs.get('lc2')\n",
    "        lc3 = kwargs.get('lc3')\n",
    "        lc4 = kwargs.get('lc4')\n",
    "        lc5 = kwargs.get('lc5')\n",
    "        lc6 = kwargs.get('lc6')\n",
    "        lc7 = kwargs.get('lc7')\n",
    "\n",
    "        lcspec1 = kwargs.get('lcspec1')\n",
    "        lcspec2 = kwargs.get('lcspec2')\n",
    "\n",
    "        lc2dbl = kwargs.get('lc2dbl')\n",
    "\n",
    "        self.class_list = [lc for lc in [lc1,lc2,lc3,lc4,lc5,lc6,lc7] if lc is not None]\n",
    "        self.class_spec_list = [lc for lc in [lcspec1, lcspec2] if lc is not None]\n",
    "        \n",
    "        self.hd_class = self.filter_level3_subset()\n",
    "        self.hd_spec_class = self.filter_level4_subset()\n",
    "        self.hd_sglcrp = self.single_cropping()\n",
    "        self.hd_dblcrp = self.double_cropping(lc2dbl = lc2dbl)\n",
    "\n",
    "    def filter_level3_subset(self):\n",
    "\n",
    "        hd_class = pd.DataFrame()\n",
    "        for i in self.class_list:\n",
    "            condition1 = (self.hd_data['survey_lc1'].notnull()) & (self.hd_data['survey_lc2'].str.slice(0,3) == i)\n",
    "            for j in range(0,len(self.class_list)):\n",
    "                condition2 = (self.hd_data['survey_lc1'].str.slice(0,3) == i) & (self.hd_data['survey_lc2'].str.slice(0,3) == self.class_list[j])\n",
    "            condition3 = (self.hd_data['survey_lc1'].str.slice(0,3) == i) & (self.hd_data['survey_lc2']  == '8 - Not relevant')\n",
    "\n",
    "            filtered_hd_data = self.hd_data[condition1|condition2|condition3]\n",
    "            hd_class = pd.concat([hd_class, filtered_hd_data], ignore_index=True)\n",
    "\n",
    "        return hd_class\n",
    "\n",
    "    def filter_level4_subset(self):\n",
    "\n",
    "        hd_class = pd.DataFrame()\n",
    "        for i in self.class_spec_list:\n",
    "            condition1 = (self.hd_data['survey_lc1_spec'].notnull()) & (self.hd_data['survey_lc2_spec'].str.slice(0,4) == i)\n",
    "            for j in range(0,len(self.class_spec_list)):\n",
    "                condition2 = (self.hd_data['survey_lc1_spec'].str.slice(0,4) == i) & (self.hd_data['survey_lc2_spec'].str.slice(0,4) == self.class_spec_list[j])\n",
    "            condition3 = (self.hd_data['survey_lc1_spec'].str.slice(0,4) == i) & (self.hd_data['survey_lc2_spec']  == '8 - Not relevant')\n",
    "\n",
    "            filtered_hd_data = self.hd_data[condition1|condition2|condition3]\n",
    "            hd_class = pd.concat([hd_class, filtered_hd_data], ignore_index=True)\n",
    "\n",
    "        return hd_class\n",
    "    \n",
    "    def single_cropping(self):\n",
    "\n",
    "        sglcrps = pd.DataFrame()\n",
    "        if self.class_list:\n",
    "            for i in self.class_list:\n",
    "                sglcrp = self.hd_class[((self.hd_class['survey_lc1'].str.slice(0,3) == i) & (self.hd_class['survey_lc2'] == '8 - Not relevant'))]\n",
    "                sglcrps = pd.concat([sglcrps, sglcrp], ignore_index=True)\n",
    "            return sglcrps\n",
    "        if self.class_spec_list:\n",
    "            for i in self.class_spec_list:\n",
    "                sglcrp = self.hd_spec_class[((self.hd_spec_class['survey_lc1_spec'].str.slice(0,4) == i) & (self.hd_spec_class['survey_lc2_spec'] == '8 - Not relevant'))]\n",
    "                sglcrps = pd.concat([sglcrps, sglcrp], ignore_index=True)\n",
    "            return sglcrps\n",
    "\n",
    "    def double_cropping(self, lc2dbl):\n",
    "\n",
    "        lc2dbl = str(lc2dbl)\n",
    "        # dblcrps = pd.DataFrame()\n",
    "        if self.class_list: \n",
    "            dblcrps = self.hd_class[((self.hd_class['survey_lc1'].str.slice(0,3) == self.class_list[0]) & (self.hd_class['survey_lc2'].str.slice(0,3) == lc2dbl))|\n",
    "                            ((self.hd_class['survey_lc1'].str.slice(0,3) == lc2dbl) & (self.hd_class['survey_lc2'].str.slice(0,3) == self.class_list[0]))]\n",
    "            return dblcrps\n",
    "        if self.class_spec_list:\n",
    "            dblcrps = self.hd_spec_class[((self.hd_spec_class['survey_lc1_spec'].str.slice(0,4) == self.class_spec_list[0]) & (self.hd_spec_class['survey_lc2'].str.slice(0,3) == lc2dbl)) |\n",
    "                            ((self.hd_spec_class['survey_lc1'].str.slice(0,3) == lc2dbl) & (self.hd_spec_class['survey_lc2'].str.slice(0,4) == self.class_spec_list[0]))]\n",
    "            return dblcrps\n",
    "\n",
    "\n",
    "    def create_hd_gdf(self, input_data):\n",
    "\n",
    "        data = input_data\n",
    "        year = self.year\n",
    "        hd_gdf = gpd.GeoDataFrame({\n",
    "            'point_id': [],\n",
    "            f'survey_date_{year}': [],\n",
    "            f'survey_year_{year}': [],\n",
    "            'nuts0' :[], \n",
    "            'nuts1' :[],\n",
    "            'nuts2' : [],\n",
    "            'nuts3'  : [],\n",
    "            'poly_area_sqm' : [], \n",
    "            f'lc1_{year}' : [],\n",
    "            f'lc2_{year}' : [],\n",
    "            f'lc3_{year}' : [],\n",
    "            f'lc1_spec_{year}':[],\n",
    "            f'lc2_spec_{year}':[],\n",
    "            f'lc_eo4bk_{year}': [],\n",
    "            f'survey_wm_{year}' :[],\n",
    "            f'survey_wm_type_{year}':[],\n",
    "            f'survey_wm_source_{year}':[],\n",
    "            f'survey_wm_delivery_{year}':[],\n",
    "            # 'survey_wm_reclaim_signs':[],\n",
    "            # 'survey_inspire_unvegetated':[],\n",
    "            # 'survey_lm_stand_veget':[],\n",
    "            # 'survey_lm_by_veget':[],\n",
    "            f'survey_lm_crop_resid_{year}':[],\n",
    "            # 'survey_lm_crop_resid_perc':[],\n",
    "            f'survey_lc_lu_special_remark_{year}':[],\n",
    "            'geometry': []\n",
    "            }, crs=self.hd_data.crs)\n",
    "\n",
    "    \n",
    "        hd_gdf['point_id']                   = data['point_id'].astype(str)\n",
    "        hd_gdf[f'survey_date_{year}']                = pd.to_datetime(data['survey_date'])\n",
    "        hd_gdf[f'survey_year_{year}']                = data['survey_year']\n",
    "        hd_gdf['nuts0']                      = data['nuts0'].astype(str)\n",
    "        hd_gdf['nuts1']                      = data['nuts1'].astype(str)\n",
    "        hd_gdf['nuts2']                      = data['nuts2'].astype(str)\n",
    "        hd_gdf['nuts3']                      = data['nuts3'].astype(str)\n",
    "        hd_gdf['poly_area_sqm']              = round(data['poly_area_sqm'].astype(float), 2)\n",
    "        hd_gdf[f'lc1_{year}']                        = data['survey_lc1']\n",
    "        hd_gdf[f'lc2_{year}']                        = data['survey_lc2']\n",
    "        hd_gdf[f'lc3_{year}']                        = data['surveycprnlc']  \n",
    "        hd_gdf[f'lc1_spec_{year}']                   = data['survey_lc1_spec']  \n",
    "        hd_gdf[f'lc2_spec_{year}']                   = data['survey_lc2_spec']  \n",
    "        hd_gdf[f'lc_eo4bk_{year}']                   = self.eo4bkclass\n",
    "        hd_gdf[f'survey_wm_{year}']                  = data['survey_wm']  \n",
    "        hd_gdf[f'survey_wm_type_{year}']             = data['survey_wm_type']  \n",
    "        hd_gdf[f'survey_wm_source_{year}']           = data['survey_wm_source']  \n",
    "        hd_gdf[f'survey_wm_delivery_{year}']         = data['survey_wm_delivery']  \n",
    "        try:\n",
    "            hd_gdf[f'survey_wm_reclaim_signs_only_{year}']    = data['survey_wm_reclaim_signs'] \n",
    "            hd_gdf[f'survey_inspire_unvegetated_only_{year}']  = data['survey_inspire_unvegetated']  \n",
    "            hd_gdf[f'survey_lm_stand_veget_only_{year}']       = data['survey_lm_stand_veget'] \n",
    "            hd_gdf[f'survey_lm_by_veget_only_{year}']          = data['survey_lm_by_veget']  \n",
    "            hd_gdf[f'survey_lm_crop_resid_perc_only_{year}']   = data['survey_lm_crop_resid_perc']  \n",
    "        except KeyError:\n",
    "            pass\n",
    "        hd_gdf[f'survey_lc_lu_special_remark_{year}'] = data['survey_lc_lu_special_remark']\n",
    "        hd_gdf[f'survey_lm_crop_resid_{year}']        = data['survey_lm_crop_resid']  \n",
    "        hd_gdf['geometry']                    = data.geometry\n",
    "\n",
    "        return hd_gdf\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create Function to merge low detail level and high detail level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_gdfs(ld_gdf, hd_gdf):\n",
    "    eo4bk_gdf = pd.concat([ld_gdf, hd_gdf], ignore_index = True, sort = False)\n",
    "    return eo4bk_gdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create final EO4BKLUCAS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new classdict after the changes made in the nomenclature according to the D1.1 document from the 05.11.2024\n",
    "\n",
    "classdic = {\"Wheat\" : {'lc1': 'B11',\n",
    "                       'lc2':'B12'},\n",
    "            \"Barley\":{'lc1':'B13'},\n",
    "            \"Oats\":{'lc1':'B15'},\n",
    "            \"Maize\":{'lc1':'B16'},\n",
    "            \"Rice\":{'lc1':'B17'},\n",
    "            \"Flax\":{'lcspec1':'B35a'},\n",
    "            \"Other_cereals\":{'lc1':'B19', \n",
    "                             'lc2':'B18'},\n",
    "            \"Potatoes\":{'lc1':'B21'},\n",
    "            \"Sugar_beet\":{'lc1':'B22'},\n",
    "            \"Other_root_crops\":{'lc1':'B23'},\n",
    "            \"Sunflower\":{'lc1':'B31'},\n",
    "            \"Rapeseed\":{'lc1':'B32'},\n",
    "            \"Soybean\": {'lc1' : 'B33'},\n",
    "            \"Cotton\": {'lc1':'B34'},\n",
    "            \"Sugarcane\":{'lcspec1' : 'B37e'},\n",
    "            \"Coffee\":{'lcspec1':'B84c'},\n",
    "            \"Grapes\": {'lc1' : 'B82'},\n",
    "            \"Fodder_crops\": {'lc1' : 'B53', \n",
    "                             'lc2': 'B54',\n",
    "                             'lc3':'B51',\n",
    "                             'lc4':'B52'},\n",
    "            \"Other_permanent_crop\":{'lc1' : 'B36',\n",
    "                                    'lc2':'B84'},\n",
    "            \"Other_single_crops\":{'lc1':'B42',\n",
    "                                  'lc2':'B44',\n",
    "                                  'lc3':'B45'},\n",
    "            \"Protein_crops\":{'lc1':'B41'},\n",
    "            \"Olive_groves\":{'lc1':'B81'},\n",
    "            \"Other_grassland\":{'lc1':'E20',\n",
    "                               'lc2':'B55'}\n",
    "            \n",
    "            \n",
    "\n",
    "            }\n",
    "gdf_dict18 = {}\n",
    "gdf_dict22 = {}\n",
    "\n",
    "\n",
    "for crop, lcs  in classdic.items():\n",
    "    lc1 = lcs.get('lc1')\n",
    "    lc2 = lcs.get('lc2')\n",
    "    lc3 = lcs.get('lc3')\n",
    "    lc4 = lcs.get('lc4')\n",
    "\n",
    "    lcspec1 = lcs.get('lcspec1')\n",
    "    hd_class_function = highdetail(lcs2018_hd_data, eo4bkclass=f'{crop}',year = '2018', lc1 = lc1, lc2 = lc2, lc3 = lc3, lc4 = lc4, lcspec1 = lcspec1)\n",
    "    hd_class = hd_class_function.create_hd_gdf(hd_class_function.hd_sglcrp)\n",
    "    gdf_dict18[f'{crop}_hd'] = hd_class\n",
    "\n",
    "for crop, lcs  in classdic.items():\n",
    "    lc1 = lcs.get('lc1')\n",
    "    lc2 = lcs.get('lc2')\n",
    "    lc3 = lcs.get('lc3')\n",
    "    lc4 = lcs.get('lc4')\n",
    "    lcspec1 = lcs.get('lcspec1')\n",
    "\n",
    "    hd_class_function = highdetail(lcs2022_hd_data, eo4bkclass=f'{crop}',year = '2022', lc1 = lc1, lc2 = lc2, lc3 = lc3, lc4 = lc4, lcspec1 = lcspec1)\n",
    "    hd_class = hd_class_function.create_hd_gdf(hd_class_function.hd_sglcrp)\n",
    "    # because Flax, Sugarcane and Coffee dont have low detail class\n",
    "    if not (crop in ['Flax','Sugarcane','Coffee']):\n",
    "        ld_class_function = lowdetail(lcs2022_ld_data, eo4bkclass=f'{crop}',year = '2022', lc1 = lc1, lc2 = lc2, lc3 = lc3, lc4 = lc4)\n",
    "        ld_class = ld_class_function.create_ld_gdf()\n",
    "        \n",
    "        gdf_dict22[f'{crop}_ld'] = ld_class\n",
    "    gdf_dict22[f'{crop}_hd'] = hd_class\n",
    "\n",
    "\n",
    "\n",
    "## Fruit and Nut Orchards 2018\n",
    "\n",
    "fruitandnut_hd_class18 = highdetail(lcs2018_hd_data, eo4bkclass='Fruit_and_nut',year = '2018', lc1 = 'B71', lc2 = 'B72', lc3 = 'B73', lc4 = 'B74', lc5 = 'B75', lc6 = 'B76', lc7 = 'B77')\n",
    "gdf_dict18['Fruit_and_nut_hd'] = fruitandnut_hd_class18.create_hd_gdf(fruitandnut_hd_class18.hd_sglcrp)\n",
    "\n",
    "\n",
    "## Fruit and Nut Orchards 2022\n",
    "\n",
    "fruitandnut_ld_class22 = lowdetail(lcs2022_ld_data, eo4bkclass='Fruit_and_nut',year = '2022', lc1 = 'B71', lc2 = 'B72', lc3 = 'B73', lc4 = 'B74', lc5 = 'B75', lc6 = 'B76', lc7 = 'B77')\n",
    "fruitandnut_hd_class22 = highdetail(lcs2022_hd_data, eo4bkclass='Fruit_and_nut',year = '2022', lc1 = 'B71', lc2 = 'B72', lc3 = 'B73', lc4 = 'B74', lc5 = 'B75', lc6 = 'B76', lc7 = 'B77')\n",
    "gdf_dict22['Fruit_and_nut_ld'] = fruitandnut_ld_class22.create_ld_gdf()\n",
    "gdf_dict22['Fruit_and_nut_hd'] = fruitandnut_hd_class22.create_hd_gdf(fruitandnut_hd_class22.hd_sglcrp)\n",
    "\n",
    "classdic.update({'Fruit_and_nut':[]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask out conflicting LUCAS Classes\n",
    "Only for HD, consequently LD and HD have different Other Cereals, Other Root Crops, and other Fodder Crop classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset Relevant B19 class, \n",
    "# for the moment B19 includes B19a and B19c, which are now an exclusive class\n",
    "lc18_b19 = gdf_dict18['Other_cereals_hd'][gdf_dict18['Other_cereals_hd']['lc1_2018']=='B19']\n",
    "\n",
    "# # Exclude B19a and B19c \n",
    "lc18_b19_without_sorghum_millet = lc18_b19[(lc18_b19['lc1_spec_2018'] !='B19a')&(lc18_b19['lc1_spec_2018'] !='B19c')]\n",
    "lc18_sorghum = lc18_b19[lc18_b19['lc1_spec_2018'] =='B19a']\n",
    "lc18_millet = lc18_b19[lc18_b19['lc1_spec_2018'] =='B19c']\n",
    "\n",
    "# # Get the complete Other Cereals Class \n",
    "lc18_other_cereals = gdf_dict18['Other_cereals_hd']\n",
    "\n",
    "# # Exclude lc22_b19_without_sorghum_millet to clean other cereals from Sorghum and Millet\n",
    "lc18_other_cereals_final = lc18_other_cereals[lc18_other_cereals['point_id'].isin(lc18_b19_without_sorghum_millet['point_id'])]\n",
    "\n",
    "# Same for B23 Other Root Crops \n",
    "\n",
    "lc18_b23 = gdf_dict18['Other_root_crops_hd'][gdf_dict18['Other_root_crops_hd']['lc1_2018']=='B23']\n",
    "lc18_b23_without_fodder_crops = lc18_b23[(lc18_b23['lc1_spec_2018'] != 'B23a') & \n",
    "                                         (lc18_b23['lc1_spec_2018'] != 'B23b') & \n",
    "                                         (lc18_b23['lc1_spec_2018'] != 'B23h')]\n",
    "\n",
    "# # subset fodder crops to join eo4bkclass Fodder_crops_hd\n",
    "\n",
    "b23_fodder_crops =  lc18_b23[(lc18_b23['lc1_spec_2018'] == 'B23a') |\n",
    "                                         (lc18_b23['lc1_spec_2018'] == 'B23b') |\n",
    "                                         (lc18_b23['lc1_spec_2018'] == 'B23h')]\n",
    "\n",
    "fodder18_crops = [gdf_dict18['Fodder_crops_hd'], b23_fodder_crops]\n",
    "fodder18_crops = pd.concat(fodder18_crops)\n",
    "\n",
    "# # Rename lc_eo4bk_2022 classes \n",
    "fodder18_crops['lc_eo4bk_2018'] = 'Fodder_crops'\n",
    "lc18_sorghum['lc_eo4bk_2018'] = 'Sorghum'\n",
    "lc18_millet['lc_eo4bk_2018'] = 'Millet'\n",
    "\n",
    "# Subset Relevant B19 class, \n",
    "# for the moment B19 includes B19a and B19c, which are now an exclusive class\n",
    "lc22_b19 = gdf_dict22['Other_cereals_hd'][gdf_dict22['Other_cereals_hd']['lc1_2022']=='B19 - Other cereals']\n",
    "\n",
    "# Exclude B19a and B19c \n",
    "lc22_b19_without_sorghum_millet = lc22_b19[(lc22_b19['lc1_spec_2022'] !='B19a - Sorghum (Sorghum bicolor)')&(lc22_b19['lc1_spec_2022'] !='B19c - Common, golden or proso millet (Panicum miliaceum L.)')]\n",
    "lc22_sorghum = lc22_b19[lc22_b19['lc1_spec_2022'] =='B19a - Sorghum (Sorghum bicolor)']\n",
    "lc22_millet = lc22_b19[lc22_b19['lc1_spec_2022'] =='B19c - Common, golden or proso millet (Panicum miliaceum L.)']\n",
    "\n",
    "# Get the complete Other Cereals Class \n",
    "lc22_other_cereals = gdf_dict22['Other_cereals_hd']\n",
    "\n",
    "# Exclude lc22_b19_without_sorghum_millet to clean other cereals from Sorghum and Millet\n",
    "lc22_other_cereals_final = lc22_other_cereals[lc22_other_cereals['point_id'].isin(lc22_b19_without_sorghum_millet['point_id'])]\n",
    "\n",
    "# Same for B23 Other Root Crops \n",
    "\n",
    "lc22_b23 = gdf_dict22['Other_root_crops_hd'][gdf_dict22['Other_root_crops_hd']['lc1_2022']=='B23 - Other root crops']\n",
    "lc22_b23_without_fodder_crops = lc22_b23[(lc22_b23['lc1_spec_2022'] != 'B23a - Fodder beet (roots of Beta vulgaris)') & \n",
    "                                         (lc22_b23['lc1_spec_2022'] != 'B23b - Fodder kale (Brassica oleracea L.)') & \n",
    "                                         (lc22_b23['lc1_spec_2022'] != 'B23h - Fodder parsnips (Pastinaca sativa L.)')]\n",
    "\n",
    "# subset fodder crops to join eo4bkclass Fodder_crops_hd\n",
    "\n",
    "b23_fodder_crops =  lc22_b23[(lc22_b23['lc1_spec_2022'] == 'B23a - Fodder beet (roots of Beta vulgaris)') |\n",
    "                                         (lc22_b23['lc1_spec_2022'] == 'B23b - Fodder kale (Brassica oleracea L.)') |\n",
    "                                         (lc22_b23['lc1_spec_2022'] == 'B23h - Fodder parsnips (Pastinaca sativa L.)')]\n",
    "\n",
    "fodder22_crops = [gdf_dict22['Fodder_crops_hd'], b23_fodder_crops]\n",
    "fodder22_crops = pd.concat(fodder22_crops)\n",
    "\n",
    "# Rename lc_eo4bk_2022 classes \n",
    "fodder22_crops['lc_eo4bk_2022'] = 'Fodder_crops'\n",
    "lc22_sorghum['lc_eo4bk_2022'] = 'Sorghum'\n",
    "lc22_millet['lc_eo4bk_2022'] = 'Millet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace old Fodder Crop with new (including B23a, B23b, B23h); \n",
    "# Replace old Other Cereals with new (excluding B19a Sorghum and B19c Millet)\n",
    "# Replace old Other Root Crops with new (lc18_b23_without_fodder_crops = excluding B23a, B23b, B23h)\n",
    "# Insert Millet and Sorghum in Dictionary \n",
    "\n",
    "gdf_dict18['Fodder_crops_hd'] = fodder18_crops\n",
    "\n",
    "gdf_dict18['Other_cereals_hd'] = lc18_other_cereals_final\n",
    "\n",
    "gdf_dict18['Other_root_crops_hd'] = lc18_b23_without_fodder_crops\n",
    "\n",
    "gdf_dict18['Millet_hd'] = lc18_millet\n",
    "\n",
    "gdf_dict18['Sorghum_hd'] = lc18_sorghum\n",
    "\n",
    "gdf_dict22['Fodder_crops_hd'] = fodder22_crops\n",
    "\n",
    "gdf_dict22['Other_cereals_hd'] = lc22_other_cereals_final\n",
    "\n",
    "gdf_dict22['Other_root_crops_hd'] = lc22_b23_without_fodder_crops\n",
    "\n",
    "gdf_dict22['Millet_hd'] = lc22_millet\n",
    "\n",
    "gdf_dict22['Sorghum_hd'] = lc22_sorghum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Save EO4BKLUCAS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = list(classdic.keys())\n",
    "\n",
    "names_list.append('Millet')\n",
    "names_list.append('Sorghum')\n",
    "\n",
    "for name in names_list:\n",
    "    hd_gdf = gdf_dict22.get(f\"{name}_hd\")\n",
    "    ld_gdf = gdf_dict22.get(f\"{name}_ld\")\n",
    "    if hd_gdf is not None:\n",
    "        hd_gdf.to_file(f\"{LUCAS}/2022/{name}_2022_eo4bk.gpkg\", driver='GPKG', layer='hd_data')\n",
    "    \n",
    "    if ld_gdf is not None:\n",
    "        ld_gdf.to_file(f\"{LUCAS}/2022/{name}_2022_eo4bk.gpkg\", driver='GPKG', layer='ld_data')\n",
    "\n",
    "for name in names_list:\n",
    "    hd_gdf = gdf_dict18.get(f\"{name}_hd\")\n",
    "    if hd_gdf is not None:\n",
    "        hd_gdf.to_file(f\"{LUCAS}/2018/{name}_2018_eo4bk.gpkg\", driver = 'GPKG', layer = 'hd_data')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wp1v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
