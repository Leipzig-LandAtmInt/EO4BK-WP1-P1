{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "# from _downloadsentle_ import sentle_download\n",
    "# from _getdata_harmo_ import getdata_harmonized\n",
    "# from _create_xarray_harmo_ import create_xarray\n",
    "# from _save_xarray_ import save_as_zarr\n",
    "import torch\n",
    "import logging\n",
    "from rasterio.crs import CRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set-Up for test (in main_execute.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment\n",
    "load_dotenv()\n",
    "LUCAS = os.getenv('LUCAS_D21_V01')\n",
    "MINICUBE_OUT= os.getenv('MINICUBE_OUT_D21_V01')\n",
    "MINICUBE_DUMMYSAVE = (f'{MINICUBE_OUT}/dummyfolder') # because the new sentle update saves a .zarr file in sentle.process a new dummy-save must be made, that can is deleted. \n",
    "                                                        # The extra save in the end takes ~ 10 sec for each polygon for one year.\n",
    "\n",
    "\n",
    "lucaspoly = gpd.read_file(f'{LUCAS}/2022/Sunflower_2022_eo4bk.gpkg', layer = 'hd_data')\n",
    "\n",
    "# Target CRS must be set after changes in the sentle package\n",
    "\n",
    "targetcrs  = CRS.from_string(\"EPSG:3035\")\n",
    "\n",
    "# change time span of download period\n",
    "time_span = \"2018-01-01/2018-12-31\"\n",
    "\n",
    "# because polygons less then 100 sqm are smaller than one pixel\n",
    "lucaspoly_ov_100sqm = lucaspoly[lucaspoly['poly_area_sqm'] > 100]\n",
    "\n",
    "# id_list is needed to iterate \n",
    "id_list = list(lucaspoly_ov_100sqm['point_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test: from _downloadsentle_ import sentle_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/home/dschierbaum/.conda/envs/wp1v3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentle import sentle \n",
    "import rioxarray\n",
    "from shapely.geometry import mapping \n",
    "import geopandas as gpd\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentle_download(lcs_eo4bkdata, time_span:str ):\n",
    "    '''\n",
    "    This function downloads the Sentinel data\n",
    "    '''\n",
    "\n",
    "\n",
    "    boundary = lcs_eo4bkdata.geometry.bounds\n",
    "    bound_left = int(boundary.minx.iloc[0])\n",
    "    bound_bottom = int(boundary.miny.iloc[0])\n",
    "    bound_right = int(boundary.maxx.iloc[0])\n",
    "    bound_top = int(boundary.maxy.iloc[0])\n",
    "    \n",
    "    sentle.process(target_crs= targetcrs,\n",
    "                   zarr_store = MINICUBE_DUMMYSAVE,\n",
    "                   bound_left=bound_left,\n",
    "                   bound_bottom=bound_bottom,\n",
    "                   bound_right=bound_right,\n",
    "                   bound_top=bound_top,\n",
    "                   datetime=time_span,\n",
    "                   target_resolution=10,\n",
    "                   S2_mask_snow=True,\n",
    "                   S2_cloud_classification=True,\n",
    "                   S2_cloud_classification_device=\"cuda\",\n",
    "                   S1_assets=[\"vv\", \"vh\"],\n",
    "                   S2_apply_snow_mask=True,\n",
    "                   S2_apply_cloud_mask=True,\n",
    "                   time_composite_freq=\"7d\",\n",
    "                   num_workers=40\n",
    "                   )\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/home/dschierbaum/.conda/envs/wp1v3/lib/python3.12/site-packages/sentle/reproject_util.py:10: UserWarning: Specified top/bottom bounds are not perfectly divisable by specified target_resolution. The resulting coverage will be rounded up to the next pixel value.\n",
      "  warnings.warn(\n",
      "/net/home/dschierbaum/.conda/envs/wp1v3/lib/python3.12/site-packages/sentle/reproject_util.py:17: UserWarning: Specified left/right bounds are not perfectly divisable by specified target_resolution. The resulting coverage will be rounded up to the next pixel value.\n",
      "  warnings.warn(\n",
      "processing: 100%|██████████| 104/104 [06:06<00:00,  3.52s/ptiles]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AutoProxy[Queue]' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test function \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# testpoly would be the first iterative of foorloop \u001b[39;00m\n\u001b[1;32m      3\u001b[0m testpoly \u001b[38;5;241m=\u001b[39m lucaspoly_ov_100sqm[lucaspoly_ov_100sqm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoint_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m id_list[\u001b[38;5;241m15\u001b[39m]]\n\u001b[0;32m----> 4\u001b[0m \u001b[43msentle_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_span\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36msentle_download\u001b[0;34m(lcs_eo4bkdata, time_span)\u001b[0m\n\u001b[1;32m     10\u001b[0m bound_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(boundary\u001b[38;5;241m.\u001b[39mmaxx\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     11\u001b[0m bound_top \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(boundary\u001b[38;5;241m.\u001b[39mmaxy\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m \u001b[43msentle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_crs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtargetcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m               \u001b[49m\u001b[43mzarr_store\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMINICUBE_DUMMYSAVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbound_left\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbound_left\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbound_bottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbound_bottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbound_right\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbound_right\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbound_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbound_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtarget_resolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m               \u001b[49m\u001b[43mS2_mask_snow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m               \u001b[49m\u001b[43mS2_cloud_classification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m               \u001b[49m\u001b[43mS2_cloud_classification_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m               \u001b[49m\u001b[43mS1_assets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m               \u001b[49m\u001b[43mS2_apply_snow_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m               \u001b[49m\u001b[43mS2_apply_cloud_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtime_composite_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m7d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m               \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[43m               \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/wp1v3/lib/python3.12/site-packages/sentle/sentle.py:651\u001b[0m, in \u001b[0;36mprocess\u001b[0;34m(target_crs, target_resolution, bound_left, bound_bottom, bound_right, bound_top, datetime, zarr_store, processing_spatial_chunk_size, S1_assets, S2_mask_snow, S2_cloud_classification, S2_cloud_classification_device, S2_return_cloud_probabilities, num_workers, time_composite_freq, S2_apply_snow_mask, S2_apply_cloud_mask, overwrite)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S2_cloud_classification:\n\u001b[1;32m    650\u001b[0m     cloud_request_queue\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 651\u001b[0m     \u001b[43mcloud_request_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m()\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;66;03m# close response queues manager\u001b[39;00m\n\u001b[1;32m    654\u001b[0m     GLOBAL_QUEUE_MANAGER\u001b[38;5;241m.\u001b[39mshutdown()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoProxy[Queue]' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "# Test function \n",
    "# testpoly would be the first iterative of foorloop \n",
    "testpoly = lucaspoly_ov_100sqm[lucaspoly_ov_100sqm['point_id']== id_list[15]]\n",
    "sentle_download(testpoly, time_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test: from _getdata_harmo_ import getdata_harmonized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "import spyndex\n",
    "\n",
    "def getdata_harmonized(output_download, lcs_eo4bkdata):\n",
    "\n",
    "    '''\n",
    "    This function gets the data from LUCAS and from Sentinel Download / and calculates indices, because they are not directly available in sentle\n",
    "    '''\n",
    "    sen_data = output_download.sentle\n",
    "    lcs_eo4bkdata = lcs_eo4bkdata\n",
    "    # eo4bkdata_lcs_xarray = lcs_eo4bkdata.to_xarray()\n",
    "\n",
    "    # get LUCAS data\n",
    "\n",
    "    point_id = lcs_eo4bkdata['point_id'].values.astype(str)\n",
    "\n",
    "    # get all the bands from the sentinel download\n",
    "    b01 = sen_data.sel(band = 'B01').data\n",
    "    b02 = sen_data.sel(band = 'B02').data\n",
    "    b03 = sen_data.sel(band = 'B03').data\n",
    "    b04 = sen_data.sel(band = 'B04').data\n",
    "    b05 = sen_data.sel(band = 'B05').data\n",
    "    b06 = sen_data.sel(band = 'B06').data\n",
    "    b07 = sen_data.sel(band = 'B07').data\n",
    "    b08 = sen_data.sel(band = 'B08').data\n",
    "    b08a = sen_data.sel(band = 'B8A').data\n",
    "    b09 = sen_data.sel(band = 'B09').data\n",
    "    b11 = sen_data.sel(band = 'B11').data\n",
    "    b12 = sen_data.sel(band = 'B12').data\n",
    "    vh = sen_data.sel(band = 'vh').data\n",
    "    vv = sen_data.sel(band = 'vv').data    \n",
    "    \n",
    "    # get dimension data from sentinel download\n",
    "\n",
    "    lon = sen_data.x.data\n",
    "    lat = sen_data.y.data\n",
    "    time = np.array(sen_data.time.data, dtype='datetime64[ns]')\n",
    "    \n",
    " \n",
    "    ## Calculate Indicies \n",
    "        \n",
    "    # NDVI \n",
    "    ndvi = spyndex.computeIndex(\n",
    "        index = [\"NDVI\"],\n",
    "        params = {\n",
    "            \"N\" : b08,\n",
    "            \"R\" : b04\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # NIRv\n",
    "\n",
    "    nirv = spyndex.computeIndex(\n",
    "        index = [\"NIRv\"],\n",
    "        params = {\n",
    "            \"N\" : b08,\n",
    "            \"R\" : b04\n",
    "        }\n",
    "        \n",
    "    )\n",
    "    # kNDVI\n",
    "    params = {\n",
    "        \"kNN\" : 1.0,\n",
    "        \"kNR\" : spyndex.computeKernel(\n",
    "            kernel = \"RBF\",\n",
    "            params = {\"a\": b08,\n",
    "                      \"b\": b04,\n",
    "                      \"sigma\": 0.5 *( b08 + b04)}\n",
    "                      ),\n",
    "            }\n",
    "\n",
    "    kndvi = spyndex.computeIndex(\"kNDVI\", params)\n",
    "\n",
    "    return {\n",
    "        \"point_id\": point_id,\n",
    "        \"lon\":  lon,\n",
    "        \"lat\":  lat,\n",
    "        \"time\": time,\n",
    "        \"b01\":  b01,\n",
    "        \"b02\":  b02,\n",
    "        \"b03\" : b03,\n",
    "        \"b04\":  b04,\n",
    "        \"b05\" : b05,\n",
    "        \"b06\" : b06,\n",
    "        \"b07\" : b07, \n",
    "        \"b08\" : b08,\n",
    "        \"b08a\": b08a,\n",
    "        \"b09\" : b09,\n",
    "        \"b11\" : b11,\n",
    "        \"b12\" : b12,\n",
    "        \"vh\"  : vh,\n",
    "        \"vv\"  : vv,    \n",
    "        \"ndvi\": ndvi,\n",
    "        \"nirv\": nirv,\n",
    "        \"kndvi\": kndvi\n",
    "        \n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentle_dummy_save = xr.open_zarr(f'{MINICUBE_DUMMYSAVE}')\n",
    "\n",
    "variables = getdata_harmonized(sentle_dummy_save, testpoly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test: from _create_xarray_harmo_ import create_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from _create_lucas_attributes_ import create_lucas_attributes\n",
    "from _create_sentinel_attributes_ import create_sentinel_attributes\n",
    "\n",
    "\n",
    "def create_xarray(variables):\n",
    "    \n",
    "\n",
    "    '''\n",
    "    This function creates an xarray with the corresponding attributes \n",
    "    '''\n",
    "\n",
    "    lat = variables['lat']\n",
    "    lon = variables['lon']\n",
    "    time = variables['time']\n",
    "    # time = np.datetime64(variables['time']) # Ensure proper datetime precision\n",
    "\n",
    "    sent_keys = ['b01', 'b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b08', 'b08a', 'b09', 'b11', 'b12', 'vh', 'vv', 'ndvi', 'nirv', 'kndvi']\n",
    "    data_vars = {}\n",
    "\n",
    "    # Populate data_vars with Sentinel variables\n",
    "    for key in sent_keys:\n",
    "        if key in variables:\n",
    "            data_vars[f'sent_{key}'] = ([\"time\", \"lat\", \"lon\"], variables[key])\n",
    "\n",
    "    # Add LUCAS point ID\n",
    "    data_vars['lcs_point_id'] = ([\"index\"], variables['point_id'])\n",
    "\n",
    "    # Create the xarray Dataset\n",
    "    datacube = xr.Dataset(\n",
    "        coords=dict(\n",
    "            lon=(\"lon\", lon),\n",
    "            lat=(\"lat\", lat),\n",
    "            time=(\"time\", time)\n",
    "        ),\n",
    "        data_vars=data_vars\n",
    "    )\n",
    "\n",
    "  ## Pass the attributes       \n",
    "    # Global attributes \n",
    "    datacube.attrs['acknowledgment'] = 'All EO4BK data providers are acknowledged inside each variable'\n",
    "    datacube.attrs['Description'] = 'Data variables with the prefix \"sent_\" are referring to Sentinel variables, \\nData varaibales with the prefix \"lcs_\" are referring to LUCAS variables'\n",
    "            # Local Sentinel-2 attributes \n",
    "\n",
    "    # # get the attributes from the create_attributes directory\n",
    "    for band, attr in create_sentinel_attributes()[0].items():                                   # Parallel iteration through band and attr, where elements of sentinel_attributes.items() is unpacked in key and value pair \n",
    "        datacube[f'sent_{band}'].attrs['long_name'] = attr['long_name']          # key is in reference of the current key, and value gets the reference for the value\n",
    "        datacube[f'sent_{band}'].attrs['Wavelength S2A'] = attr['Wavelength S2A']\n",
    "        datacube[f'sent_{band}'].attrs['Wavelentgh S2B'] = attr['Wavelength S2B']\n",
    "        datacube[f'sent_{band}'].attrs['Original Resolution'] = attr['Original resolution']\n",
    "        datacube[f'sent_{band}'].attrs['Pixel Size'] = attr['Pixel Size']\n",
    "        datacube[f'sent_{band}'].attrs['Processing Steps'] = attr['Processing steps']\n",
    "    for band, attr in create_sentinel_attributes()[1].items():\n",
    "        datacube[f'sent_{band}'].attrs['long_name'] = attr['long_name']\n",
    "        datacube[f'sent_{band}'].attrs['Description'] = attr['Additional Description']\n",
    "        datacube[f'sent_{band}'].attrs['Usage'] = attr['Usage']\n",
    "        datacube[f'sent_{band}'].attrs['Original Resolution'] = attr['Original resolution']\n",
    "        datacube[f'sent_{band}'].attrs['Pixel Size'] = attr['Pixel Size']\n",
    "        datacube[f'sent_{band}'].attrs['Processing Steps'] = attr['Processing steps']\n",
    "    for band, attr in create_sentinel_attributes()[2].items():\n",
    "        datacube[f'sent_{band}'].attrs['long_name'] = attr['long_name']\n",
    "        datacube[f'sent_{band}'].attrs['Processing Steps'] = attr['Processing Steps']\n",
    "        datacube[f'sent_{band}'].attrs['Pixel Size'] = attr['Pixel Size']\n",
    "\n",
    "    # # get the lucas attributes from the lucas_core_directory, because of lucas hd and ld input differences it must be flexible\n",
    "    \n",
    "    for var, attr in create_lucas_attributes(variables['point_id']).items():\n",
    "        datacube[f'lcs_{var}'].attrs['long_name'] = attr['long_name']\n",
    "        datacube[f'lcs_{var}'].attrs['Description'] = attr['description']\n",
    "        datacube[f'lcs_{var}'].attrs['Value Origin'] = attr['value_origin']\n",
    "        datacube[f'lcs_{var}'].attrs['Original Name'] = attr['original_name']\n",
    "        datacube[f'lcs_{var}'].attrs['Acknowledgment'] = attr['acknowledgement']\n",
    "        datacube[f'lcs_{var}'].attrs['PID'] = attr['PID']\n",
    "        datacube[f'lcs_{var}'].attrs['How to cite'] = attr['How to cite']\n",
    "        datacube[f'lcs_{var}'].attrs['Download link'] = attr['Download_link']\n",
    "        datacube[f'lcs_{var}'].attrs['Detailed description'] = attr.get('Detailed_description', 'No detailed description available')\n",
    "        datacube[f'lcs_{var}'].attrs['Processing Step'] = attr.get('processing_steps', 'Processing is conducted by LUCAS')\n",
    "\n",
    "    # here the difference from the processing steps between lucas hd and ld are considered\n",
    "\n",
    "\n",
    "    return datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = create_xarray(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test: from _save_xarray_ import save_as_zarr\n",
    "\n",
    "Add an import shutill, shutil.rmtree() to remove the dummy_save from the sentle update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "import os\n",
    "import shutil \n",
    "\n",
    "# # is for logging\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,  # Set the desired logging level\n",
    "#     format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "#     handlers=[\n",
    "#         logging.StreamHandler(),  # Logs to the console\n",
    "#         logging.FileHandler('sentinel_processing_2510.log')  # Logs to a file\n",
    "#     ]\n",
    "# )\n",
    "# logger = logging.getLogger()\n",
    "\n",
    "# function saves the zarr\n",
    "def save_as_zarr(output_eo4bk_minicube, lcs_eo4bkdata, main_direction, hd = True):\n",
    "    '''\n",
    "    This function save the data from xarray_output to a zarr file\n",
    "    '''\n",
    "    # keys = output_eo4bk_minicube.keys()\n",
    "    # da = output_eo4bk_minicube #[f'{list(keys)[0]}']\n",
    "\n",
    "    main_direction = main_direction\n",
    "    \n",
    "    # is to create different folders for ld and hd data. \n",
    "    if hd == True:\n",
    "        detail = 'hd'\n",
    "    else:\n",
    "        detail = 'ld'\n",
    "\n",
    "    # defines the output direction\n",
    "    if 'lc_eo4bk_2022' in lcs_eo4bkdata:\n",
    "        eo4bkclass =lcs_eo4bkdata['lc_eo4bk_2022'].iloc[0]\n",
    "\n",
    "    elif 'lc_eo4bk_2018' in lcs_eo4bkdata:\n",
    "        eo4bkclass = lcs_eo4bkdata['lc_eo4bk_2018'].iloc[0]\n",
    "            \n",
    "    nuts_0 =  lcs_eo4bkdata['nuts0'].iloc[0]\n",
    "    nuts_3 = lcs_eo4bkdata['nuts3'].iloc[0]\n",
    "    if 'survey_year_2022' in lcs_eo4bkdata:\n",
    "        year = lcs_eo4bkdata['survey_year_2022'].iloc[0]\n",
    "    elif 'survey_year_2018' in lcs_eo4bkdata:\n",
    "        year = lcs_eo4bkdata['survey_year_2018'].iloc[0]\n",
    "    dir = f'{main_direction}/{year}/{eo4bkclass}/{detail}/{nuts_0}'\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    id = lcs_eo4bkdata['point_id'].iloc[0]\n",
    "\n",
    "    #logger.info(f\"> Save the Minicube {id} ...\") # logs when it starts saving, not before, because saving is what takes the most time\n",
    "    output_eo4bk_minicube.to_zarr(f\"{dir}/{eo4bkclass}_{nuts_3}_{id}.zarr\",\n",
    "           mode = \"w\", compute = True)\n",
    "    # remove the dummy_save from the sentle update \n",
    "    shutil.rmtree(MINICUBE_DUMMYSAVE)\n",
    "    #logger.info(f\"> Successfully saved the Minicube {id} at: {dir}/{eo4bkclass}_{nuts_3}_{id}\") # logs when it is saved \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_zarr(datacube, testpoly, MINICUBE_OUT, hd = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wp1v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
